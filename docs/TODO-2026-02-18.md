# TODOs fÃ¼r 18.02.2026

Vorbereitet von Claudius ðŸ¦‘ fÃ¼r Steffen & Christopher.
Reviewed von Gemini 2.5 Pro â€” Feedback eingearbeitet.

---

## 1. ðŸ“Š Token-Tracking pro Benutzer â€” PrioritÃ¤t: SEHR HOCH

**Ziel:** Ãœbersicht welcher Nutzer welches Modell wie oft/viel nutzt + Kosten. Sichtbar im Profil (Steffen, Christopher, Micha).

### Datenmodell
```sql
CREATE TABLE token_usage (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    teacher_id UUID REFERENCES teachers(id),
    model TEXT NOT NULL,              -- z.B. 'claude-sonnet-4', 'claude-3-5-haiku'
    input_tokens INTEGER DEFAULT 0,
    output_tokens INTEGER DEFAULT 0,
    cost_usd NUMERIC(10, 6),         -- âš¡ Gemini: Kosten sofort mitberechnen!
    agent_type TEXT,                  -- 'main', 'klausur', 'memory', etc.
    request_id UUID,                  -- Anfragen gruppieren
    created_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX idx_token_usage_teacher ON token_usage(teacher_id);
CREATE INDEX idx_token_usage_date ON token_usage(created_at);
```

### Preistabelle (hartcodiert, als Dict im Backend)
```python
MODEL_PRICES = {  # USD pro 1M Tokens
    "claude-sonnet-4": {"input": 3.0, "output": 15.0},
    "claude-3-5-haiku": {"input": 0.80, "output": 4.0},
}
```

### Backend
- **Logging via `background_task`** (nicht Fire-and-forget!) â€” FastAPI Background Tasks mit Retry
- Pydantic AI gibt `result.usage()` zurÃ¼ck mit `input_tokens`, `output_tokens`
- Kosten bei Insert berechnen: `cost = (input * price_in / 1M) + (output * price_out / 1M)`
- Erfasst ALLE Agent-Calls: Main, Sub-Agents (Klausur, Memory, Curriculum, etc.)
- **Auch fehlgeschlagene Calls tracken** (Tokens werden trotzdem verbraucht!)

### API Endpoints
```
GET /api/profile/token-usage?days=7&agent_type=klausur  â†’ Tageweise, filterbar
GET /api/profile/token-usage?days=30                     â†’ MonatsÃ¼bersicht
```

Response:
```json
{
  "daily": [
    { "date": "2026-02-18", "model": "claude-sonnet-4", "input_tokens": 12400, "output_tokens": 8200, "calls": 15, "cost_usd": 0.16 }
  ],
  "total": { "input_tokens": 15600, "output_tokens": 10000, "calls": 23, "cost_usd": 0.20 }
}
```

### Frontend (ProfilePage)
- Neue Section "Token-Verbrauch" im Profil
- Tabelle: Datum | Modell | Input | Output | Kosten | Calls
- Filterbar nach `agent_type`
- Optional: Kleines Balkendiagramm pro Tag (CSS-only)

### Aufwand: ~4-6h (korrigiert nach Gemini-Review)
- DB + RLS Policies: 30 min
- Backend Hook + Retry + Preisberechnung: 1.5h
- API mit Aggregation + Filtern: 45 min
- Frontend: 1.5h
- Testing: 1h

### âš ï¸ Risiken (Gemini)
- Performance bei groÃŸer Tabelle â†’ spÃ¤ter MATERIALIZED VIEW oder Archivierung
- UnvollstÃ¤ndiges Tracking bei Timeouts/AbbrÃ¼chen

---

## 2. ðŸ”˜ RÃ¼ckfrage-Cards mit Klick-Buttons â€” PrioritÃ¤t: MITTEL

**Ziel:** Wenn der Agent Optionen zur Auswahl gibt â†’ klickbare Buttons statt FlieÃŸtext.

### Ist-Zustand âœ…
- `ClarificationCard.tsx` existiert
- `ask_teacher` Tool mit `options`-Feld existiert
- Frontend zeigt Optionen als Buttons
- Klick â†’ Text-Nachricht â†’ funktioniert

### Was zu tun ist
1. **Konsistenz-Regel**: "Jede binÃ¤re oder Multiple-Choice-Frage an den User MUSS Ã¼ber `ask_teacher` mit `options` laufen" â€” als Prompt-Snippet in `base.py`
2. **Alle 12 Agents durchgehen**: PrÃ¼fen ob RÃ¼ckfragen `options` setzen
3. **Styling verbessern**: Buttons prominenter, ggf. Icons
4. **Fallback**: Wenn User trotzdem Text tippt statt zu klicken â†’ muss trotzdem funktionieren

### ~~Multi-Step Wizard~~ â†’ Eigenes Epic (Gemini-Empfehlung)
Aus diesem Task gestrichen. Erfordert State Machine + eigenes Konzept.

### Referenz: Claude.ai
"Suggested replies" als Chips. Unser `ClarificationNeededError` + `options` ist analog.

### Aufwand: ~1-2h
- Prompt-Snippet + Agents anpassen: 30 min
- Frontend Polish: 30 min
- Testing: 30 min

---

## 3. â³ Agent-Arbeitsanzeige (Pulsing Indicator) â€” PrioritÃ¤t: MITTEL

**Ziel:** User sieht DASS der Agent arbeitet. Nicht stiller Textstream.

### Ist-Zustand
- SSE Streaming existiert âœ…
- Tool-Call-Schritte als `[ðŸ”§ Tool wird ausgefÃ¼hrt...]` âœ…
- Material-Generierung: Agent denkt lange, dann alles auf einmal âŒ

### GewÃ¼nschtes Verhalten
1. **Schritt-Anzeige**: "ðŸ” Analysiere Anforderungen..." â†’ "ðŸ“ Erstelle Aufgaben..." â†’ "âœ… Fertig!"
2. **Pulsing-Animation**: CSS-Animation sichtbar
3. **Ergebnis in eigener Nachricht**: Nicht inline im Stream

### Technische Umsetzung
- SSE Events erweitern: `event: step`
  ```json
  { "step_name": "Erstelle Klausur...", "current_step": 2, "total_steps": 3 }
  ```
  *(Gemini: Keine Prozent-Anzeige â€” LLMs denken nicht linear. Step-Counter stattdessen.)*
- Frontend: `StepIndicator.tsx` mit Pulse-Animation
- **V1: Statische Schritte** ("Rufe Agent auf...", "Formatiere...") â€” reicht fÃ¼r den Anfang
- Material-Ergebnis als eigene "Nachricht" im Chat

### Aufwand: ~2-3h
- Backend SSE Steps (statisch): 1h
- Frontend StepIndicator: 1h
- Integration + Test: 1h

---

## 4. ðŸ§  Memory-System Review & Restructuring â€” PrioritÃ¤t: HOCH

**Ziel:** Memory analysieren, aufrÃ¤umen, fÃ¼r User sichtbar machen, STM/LTM explizit trennen.

### Ist-Zustand
- **Tabelle**: `user_memories` (Supabase)
- **Felder**: `id, teacher_id, category, key, value, created_at, updated_at, access_count`
- **~231 EintrÃ¤ge** (nach Dedup von 266) fÃ¼r Steffen
- **Top 50** per Recency+Relevancy im System-Prompt (~854 Tokens)
- **Memory-Agent** (Haiku): Fire-and-forget nach jeder Nachricht
- **Problem**: Massive Duplikation

### Phase 1: Analyse (SQL zuerst!)
```sql
-- Memories pro Teacher
SELECT teacher_id, COUNT(*) FROM user_memories GROUP BY teacher_id;

-- Kategorien-Verteilung
SELECT category, COUNT(*) FROM user_memories 
WHERE teacher_id = 'STEFFEN_ID' GROUP BY category ORDER BY count DESC;

-- Duplikate
SELECT value, COUNT(*) as cnt FROM user_memories 
WHERE teacher_id = 'STEFFEN_ID' GROUP BY value HAVING COUNT(*) > 1;

-- Durchschnittliches Alter
SELECT AVG(EXTRACT(EPOCH FROM (now() - created_at))/86400) as avg_days 
FROM user_memories WHERE teacher_id = 'STEFFEN_ID';
```

### Phase 2: STM/LTM Modell (Christopher)

| Aspekt | KurzzeitgedÃ¤chtnis (STM) | LangzeitgedÃ¤chtnis (LTM) |
|--------|--------------------------|--------------------------|
| Quelle | Letzte ~30 Nachrichten (Chat History) | `user_memories` Tabelle |
| Inhalt | Aktueller Kontext, laufende Aufgaben | Preferences, Fakten, Gewohnheiten |
| Lebensdauer | Session-basiert | Permanent (mit Decay) |
| Im Prompt | Immer | Top-N nach Relevanz+Recency |
| Verwaltung | Automatisch | Memory-Agent + Cleanup |

**Gemini**: De facto existiert dieses Modell bereits. Explizit machen + dokumentieren.

### Phase 3: Kategorien-Sortierung (Steffen)
- ðŸ‘¤ **PersÃ¶nliches**: Name, Schule, Erfahrung
- ðŸ“š **FÃ¤cher & Klassen**: Welche FÃ¤cher, welche Stufen
- ðŸŽ¯ **PrÃ¤ferenzen**: Bevorzugte Methoden, Stile
- ðŸ“‹ **Laufende Aufgaben**: Aktuelle Projekte
- ðŸ’¡ **Gelerntes**: Was der Agent gelernt hat

### Phase 4: User-Facing Memory View â€” MUSS (Gemini: kein Nice-to-have!)
```
GET /api/profile/memories              â†’ Alle Memories, kategorisiert
DELETE /api/profile/memories/:id       â†’ Einzelne Memory lÃ¶schen
PUT /api/profile/memories/:id          â†’ Memory bearbeiten
```

Frontend: Section im Profil oder eigene Seite
- Grouped by Category
- Jede Memory editierbar/lÃ¶schbar
- **"Was weiÃŸ die KI Ã¼ber mich?"** â†’ Transparenz + Vertrauen + Kontrolle

### Phase 5: Cleanup
- **Cron-Job** (3x/Tag): Duplikate mergen, alte/irrelevante lÃ¶schen
- **Admin-Endpoint**: Manuelle Batch-Bereinigung
- ~~Inline-Cleanup~~ (Gemini: erhÃ¶ht Latenz, vermeiden)

### Aufwand: ~5-6h (korrigiert nach Gemini-Review)
- Analyse (SQL): 30 min
- API Endpoints: 1h
- Frontend Memory-View: 2h
- Cleanup-Logik (die eigentliche KomplexitÃ¤tsbombe): 1.5h
- Testing: 1h

---

## Zusammenfassung

| # | Feature | Aufwand | PrioritÃ¤t |
|---|---------|---------|-----------|
| 1 | Token-Tracking + Kosten | 4-6h | ðŸ”´ Sehr Hoch |
| 2 | RÃ¼ckfrage-Buttons | 1-2h | ðŸŸ¡ Mittel |
| 3 | Agent-Arbeitsanzeige | 2-3h | ðŸŸ¡ Mittel |
| 4 | Memory-Restructuring | 5-6h | ðŸŸ  Hoch |

**Gesamt: ~12-17h Arbeit** (realistischer als die ursprÃ¼nglichen 8-12h)

### Empfohlene Reihenfolge
1. **Token-Tracking** â€” Kostentransparenz sofort (Ã¼berlebenswichtig)
2. **Memory-Analyse** (Phase 1+2) â€” Datengrundlage schaffen
3. **RÃ¼ckfrage-Buttons** â€” Quick Win
4. **Agent-Arbeitsanzeige** â€” UX Polish
5. **Memory-View + Cleanup** (Phase 3-5) â€” nach Analyse

### Benchmark-Ergebnis (Referenz)
Medium Suite: **28/30 (93%)** âœ…
- J01 Klausur: 5/5 âœ…
- J02 Differenzierung: 2/3 (Assertion zu eng)
- J03 H5P: 2/4 (Assertion zu eng)
- J04 Lehrplan: 3/3 âœ…
- J05 Stundenplanung: 3/3 âœ…
- J06 Memory: 3/3 âœ…
- J11 Multi-Turn: 4/4 âœ…
- J13 Todos: 2/2 âœ…
- QualitÃ¤t: 3/3 âœ…
